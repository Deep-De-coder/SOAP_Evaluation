{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SOAP Note Evaluation Analysis\n",
        "\n",
        "This notebook loads and analyzes the evaluation results from the SOAP note evaluation suite.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add parent directory to path to import src modules if needed\n",
        "sys.path.insert(0, str(Path().resolve().parent))\n",
        "\n",
        "# Load results\n",
        "results_dir = Path(\"../results\")\n",
        "per_note_path = results_dir / \"per_note.jsonl\"\n",
        "summary_path = results_dir / \"summary.json\"\n",
        "\n",
        "# Load per-note results\n",
        "results = []\n",
        "with open(per_note_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        results.append(json.loads(line))\n",
        "\n",
        "# Load summary\n",
        "with open(summary_path, \"r\") as f:\n",
        "    summary = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(results)} evaluation results\")\n",
        "print(f\"\\nSummary:\\n{json.dumps(summary, indent=2)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Histogram of Overall Quality Scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "overall_scores = [r[\"scores\"][\"overall_quality\"] for r in results]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(overall_scores, bins=20, edgecolor=\"black\", alpha=0.7)\n",
        "plt.xlabel(\"Overall Quality Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Overall Quality Scores\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Mean: {pd.Series(overall_scores).mean():.3f}\")\n",
        "print(f\"Std: {pd.Series(overall_scores).std():.3f}\")\n",
        "print(f\"Min: {min(overall_scores):.3f}\")\n",
        "print(f\"Max: {max(overall_scores):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Coverage vs Faithfulness Scatter Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coverage_scores = [r[\"scores\"][\"coverage\"] for r in results]\n",
        "faithfulness_scores = [r[\"scores\"][\"faithfulness\"] for r in results]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(coverage_scores, faithfulness_scores, alpha=0.6)\n",
        "plt.xlabel(\"Coverage Score\")\n",
        "plt.ylabel(\"Faithfulness Score\")\n",
        "plt.title(\"Coverage vs Faithfulness\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Compute correlation\n",
        "correlation = pd.Series(coverage_scores).corr(pd.Series(faithfulness_scores))\n",
        "print(f\"Correlation: {correlation:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Worst 5 Notes by Overall Quality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort by overall quality (ascending)\n",
        "sorted_results = sorted(results, key=lambda x: x[\"scores\"][\"overall_quality\"])\n",
        "worst_5 = sorted_results[:5]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "for i, result in enumerate(worst_5, 1):\n",
        "    print(f\"\\n{i}. Example ID: {result['example_id']}\")\n",
        "    print(f\"   Overall Quality: {result['scores']['overall_quality']:.3f}\")\n",
        "    print(f\"   Coverage: {result['scores']['coverage']:.3f}\")\n",
        "    print(f\"   Faithfulness: {result['scores']['faithfulness']:.3f}\")\n",
        "    print(f\"   Accuracy: {result['scores']['accuracy']:.3f}\")\n",
        "    print(f\"   Number of Issues: {len(result['issues'])}\")\n",
        "    \n",
        "    if result['issues']:\n",
        "        print(\"   Issues:\")\n",
        "        for issue in result['issues']:\n",
        "            print(f\"     - [{issue['severity'].upper()}] {issue['category']}: {issue['description']}\")\n",
        "            if issue.get('span_model'):\n",
        "                print(f\"       Model span: {issue['span_model'][:100]}...\")\n",
        "            if issue.get('span_source'):\n",
        "                print(f\"       Source span: {issue['span_source'][:100]}...\")\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Issue Category Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count issues by category\n",
        "issue_counts = {\"missing_critical\": 0, \"hallucination\": 0, \"clinical_inaccuracy\": 0}\n",
        "for result in results:\n",
        "    for issue in result[\"issues\"]:\n",
        "        issue_counts[issue[\"category\"]] = issue_counts.get(issue[\"category\"], 0) + 1\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "categories = list(issue_counts.keys())\n",
        "counts = list(issue_counts.values())\n",
        "plt.bar(categories, counts, color=[\"#ff6b6b\", \"#4ecdc4\", \"#ffe66d\"], edgecolor=\"black\")\n",
        "plt.xlabel(\"Issue Category\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Issues by Category\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.grid(True, alpha=0.3, axis=\"y\")\n",
        "plt.show()\n",
        "\n",
        "for category, count in issue_counts.items():\n",
        "    print(f\"{category}: {count}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
